---
title: DAGs and Confounding Part I
output:
  md_document:
    variant: gfm
    preserve_yaml: TRUE
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../_posts") })
author: "Miles Williams"
date: "2021-11-15"
excerpt: "Part I of a series"
layout: post
categories: ["DAG", "Causation"]
---

[Back to Blog](https://milesdwilliams15.github.io/blog/)

Directed acyclic graphs (DAGs) help in visualizing causal relationships
among variables. But, I have to admit, making sense of DAGs and what the
relationships they represent imply for empirical analysis is not always
easy.

So, in this first installment of what will be a series of posts, I want
to characterize some typical scenarios that researchers encounter and
use simulations to illustrate the (in)appropriateness of certain
analytical choices when attempting to recover unbiased and efficient
causal estimates. In particular, I want to document instances where
*controlling for* some variable(s) does more harm than good.

In this post I want to start with a fairly simple source of bias: **post
treatment**. Let’s begin.

## Post Treatment and d-connectedness

Suppose three variables, *x*, *y*, and *z*. Say *z* → *x* and *z* → *y*
(where → represents a causal relationship). I’ve captured this
relationship in the DAG below:

``` r
library(tidyverse)
library(seerrr)
library(ggdag)
theme_set(theme_dag())
confounder_triangle() %>%
  ggdag()
```

![](/assets/images/dags-part-1-confouding-1.png)<!-- -->

Suppose we want to recover an estimate of *z*’s effect on *y*. If we
want an unbiased and efficient estimate (why wouldn’t we?) it would be
inappropriate to control for *x* in our analysis.

Why? *x* and *y* “d-connected,” as illustrated by the below updated DAG:

``` r
confounder_triangle() %>%
  ggdag_dconnected()
```

![](/assets/images/dags-part-1-d-connected-1.png)<!-- -->

This means that *x* and *y* are related to each other due to their
mutual cause, *z*. Such a relationship does not need to be accounted for
in estimating the effect of *z* on *y*. If we were to adjust for *x* in
our analysis, this would introduce a new relationship between *x* and
*y*: that they are “d-separated”:

``` r
confounder_triangle() %>%
  ggdag_dconnected(
    controlling_for = "x"
  )
```

![](/assets/images/dags-part-1-controlling-1.png)<!-- -->

By introducing this change we run the risk of soaking up some of *z*’s
effect on *y*. I’ll illustrate first with a simulation then try to
provide some intuition for why this happens.

First, let’s simulate some data that with some simple linear
relationships between *z* and each of the effected variables, *x* and
*y*:

``` r
simulate(
  R = 10000,
  N = 500,
  z = rnorm(N),
  y = z + rnorm(N),
  x = z + rnorm(N)
) -> sim_data
```

Next, let’s estimate the effect of *z* on *y*, both with and without
adjusting for *x*:

``` r
# no adjustment for x:
estimate(
  sim_data,
  y ~ z,
  vars = "z",
  se_type = "stata"
) -> unadj

# with adjustment for x:
estimate(
  sim_data,
  y ~ z + x,
  vars = "z",
  se_type = "stata"
) -> adj
```

Now, let’s compare performance:

``` r
evaluate(
  unadj,
  what = "bias",
  truth = 1
) -> unadj_eval
evaluate(
  adj,
  what = "bias",
  truth = 1
) -> adj_eval
bind_rows(
  unadj_eval,
  adj_eval
) %>%
  mutate(
    method = c("unadjusted", "adjusted")
  ) %>%
  pivot_longer(
    cols = bias:mse
  ) %>%
  ggplot() +
  aes(
    x = value,
    y = method
  ) +
  facet_wrap(~ name) +
  geom_point() +
  geom_vline(
    xintercept = 0,
    lty = 2
  ) +
  theme_bw() +
  labs(
    x = "Estimate",
    y = NULL,
    title = "Adjusting for 'x' is no good!"
  )
```

![](/assets/images/dags-part-1-performance-1.png)<!-- -->

Controlling for *x* both worsens bias and efficiency. The reason for
this is straightforward. In a regression model where *y* is regressed on
both *z* and *z*

*y*<sub>*i*</sub> = *β*<sub>0</sub> + *β*<sub>1</sub>*z*<sub>*i*</sub> + *β*<sub>2</sub>*x*<sub>*i*</sub> + *ε*<sub>*i*</sub>,

the least squares solution for *β*<sub>1</sub> is identified using
variation in *z* not absorbed by *x* and variation in *y* not absorbed
by *x*. This is problematic because we know that *x* has no direct
effect on either of these variables. However, *x* does have a
*relationship* with each since *x* is caused by *z* and shares a cause
with *y*.

When we estimate a linear regression like that specified above using
OLS, this is equivalent to performing three separate linear regressions.
First, regressing *z* on *x*:

*z*<sub>*i*</sub> = *α*<sub>0</sub> + *α*<sub>1</sub>*x*<sub>*i*</sub> + *ν*<sub>*i*</sub>,

then regressing *y* on *x*:

*y*<sub>*i*</sub> = *δ*<sub>0</sub> + *δ*<sub>1</sub>*x*<sub>*i*</sub> + *μ*<sub>*i*</sub>,

and then finally regressing the residual variation in *y*<sub>*i*</sub>
on *z*<sub>*i*</sub>:

*μ̂*<sub>*i*</sub> = *γ* + *β*<sub>1</sub>*ν̂*<sub>*i*</sub> + *ε*<sub>*i*</sub>,

where the estimate for *β*<sub>1</sub> here is equivalent to the one
recovered from the multiple regression shown earlier.

This estimate will be incorrect because the identified relationships for
the first two regression models will be biased. While there is no true
effect of *x* on *y*, we nonetheless recover a relationship between them
in the first regression:

``` r
estimate(
  sim_data,
  y ~ x,
  vars = "x",
  se_type = "stata"
) -> xy
mean(xy$estimate) # mean recovered estimate is > 0
```

    ## [1] 0.500705

And, because *z* causes *x*, we recover a relationship between *x* and
*z* from the second regression:

``` r
estimate(
  sim_data,
  z ~ x,
  vars = "x",
  se_type = "stata"
) -> xz
mean(xz$estimate) # mean recovered estimate is > 0
```

    ## [1] 0.5000763

Consequently, variation in *z* that causes *x* is subtracted out in the
second regression—with some of the variation in *z* that causes *y*
inevitably removed as well. Further, variation in *y* caused by *z* that
also causes variation in *x* is removed in the first regression. This
puts us at a clear disadvantage in estimating the effect of *z* on *y*.

## A Simple Lesson

The lesson is simple. **Do not control for post-treatment variables**.
This may seem obvious, but this is an issue that sometimes receives
insufficient attention. Naturally, our instinct is to control for as
many variables as possible in our analysis—especially in observational
studies. But, as the case of post-treatment bias illustrates, this
approach does not always serve us well.

This is where plotting out causal relationships with a DAG can be
useful. By first thinking carefully and systematically about the
relationships that exist in your data, it is possible to hedge against
in appropriate analytical choices. DAGs, in short, can enhance your
modeling instincts and ultimately serve to make you better analyst.

There are other pitfalls beside post-treatment effects to be leery of,
however. Next time we’ll take a look at another source of bias:
*colliders*.

[Back to Blog](https://milesdwilliams15.github.io/blog/)
